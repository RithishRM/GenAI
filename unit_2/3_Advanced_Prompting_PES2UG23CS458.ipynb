{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2fe75baa",
      "metadata": {
        "id": "2fe75baa"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ba92b198",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba92b198",
        "outputId": "4be30cfe-2323-42ce-df2f-a16b7d33986f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "%pip install python-dotenv --upgrade --quiet langchain langchain-groq\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Always prompt for the API key if it's not set or invalid\n",
        "if \"GROQ_API_KEY\" not in os.environ or not os.environ[\"GROQ_API_KEY\"]:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
        "\n",
        "# Using Llama3.1-8b (Small/Fast) to demonstrate logic failures\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4a70d3b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a70d3b7",
        "outputId": "92305853-ebbe-43b8-835f-11fa6bf7173a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STANDARD (Llama3.1-8b) ---\n",
            "To find out how many cricket balls Ramesh has now, we need to add the initial number of cricket balls he had (5) to the number of cricket balls he bought (2 * 3 = 6).\n",
            "\n",
            "So, Ramesh initially had 5 cricket balls. He bought 2 cans of 3 cricket balls each, which is 6 cricket balls. \n",
            "\n",
            "Now, Ramesh has 5 + 6 = 11 cricket balls.\n"
          ]
        }
      ],
      "source": [
        "question = \"Ramesh has 5 cricket balls. He buys 2 more cans of cricket balls. Each can has 3 cricket balls. How many does he have now?\"\n",
        "\n",
        "# 1. Standard Prompt (Direct Answer)\n",
        "prompt_standard = f\"Answer this question: {question}\"\n",
        "print(\"--- STANDARD (Llama3.1-8b) ---\")\n",
        "print(llm.invoke(prompt_standard).content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3dd65b0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dd65b0a",
        "outputId": "f30b45e7-c9a6-4b2c-ab52-1da4275b4b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Chain of Thought (Llama3.1-8b) ---\n",
            "To find out how many cricket balls Ramesh has now, we need to follow these steps:\n",
            "\n",
            "1. Ramesh already has 5 cricket balls.\n",
            "2. He buys 2 more cans of cricket balls. Each can has 3 cricket balls, so he buys 2 x 3 = 6 more cricket balls.\n",
            "3. Now, we add the cricket balls he already had (5) to the new cricket balls he bought (6). So, 5 + 6 = 11.\n",
            "\n",
            "Therefore, Ramesh now has 11 cricket balls.\n"
          ]
        }
      ],
      "source": [
        "# 2. CoT Prompt (Magic Phrase)\n",
        "prompt_cot = f\"Answer this question. Let's think step by step. {question}\"\n",
        "\n",
        "print(\"--- Chain of Thought (Llama3.1-8b) ---\")\n",
        "print(llm.invoke(prompt_cot).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22ee779f",
      "metadata": {
        "id": "22ee779f"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4371aa3d",
      "metadata": {
        "id": "4371aa3d"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "%pip install python-dotenv --upgrade --quiet langchain langchain-groq\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Always prompt for the API key if it's not set or invalid\n",
        "if \"GROQ_API_KEY\" not in os.environ or not os.environ[\"GROQ_API_KEY\"]:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
        "\n",
        "# Using Llama3.1-8b\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7) # Creativity needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1ea2d4c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ea2d4c7",
        "outputId": "e45c277e-49f6-4ed1-bab8-6c86e24556aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tree of Thoughts (ToT) Result ---\n",
            "As a child psychologist, I would recommend Solution 2: \"The Gamified Study Session\" as the most sustainable approach. Here's why:\n",
            "\n",
            "1. **Encourages intrinsic motivation**: By setting up a system where your child earns points and rewards based on their effort and progress, you're encouraging them to develop an intrinsic motivation to study. This means they'll be more likely to enjoy learning for its own sake, rather than just for external rewards.\n",
            "2. **Develops self-regulation skills**: The gamified approach helps your child develop self-regulation skills, such as setting goals, tracking progress, and managing their time. These skills are essential for academic success and will benefit them throughout their lives.\n",
            "3. **Fosters a growth mindset**: By framing learning as a game, you're promoting a growth mindset, where your child sees challenges as opportunities for growth and development, rather than threats to their ego.\n",
            "4. **Encourages self-reflection**: The Gamified Study Session promotes self-reflection, as your child will need to evaluate their progress, identify areas for improvement, and adjust their strategy accordingly.\n",
            "5. **Adaptable and flexible**: This approach can be adapted to your child's individual needs and interests, making it a versatile and effective solution.\n",
            "6. **Builds a positive relationship with learning**: By turning studying into a game, you're creating a positive association with learning, which will help your child develop a lifelong love of learning.\n",
            "\n",
            "Why not Solution 1 or 3? While both solutions have their merits, I believe they may be less sustainable in the long term. Solution 1, the \"Escape Room Challenge,\" may become repetitive or boring if your child becomes too familiar with the puzzles and riddles. Solution 3, the \"Study Island,\" is a lovely idea, but it may be difficult to maintain the tropical atmosphere and novelty of the \"beach\" area, especially if your child becomes accustomed to it.\n",
            "\n",
            "In contrast, the Gamified Study Session is a more systemic approach that can be adapted and modified as your child grows and develops. It also encourages intrinsic motivation, self-regulation, and a growth mindset, making it a more sustainable and effective solution for the long term.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "problem = \"How can I get my 10-year-old to study?\"\n",
        "\n",
        "# Step 1: The Branch Generator\n",
        "prompt_branch = ChatPromptTemplate.from_template(\n",
        "    \"Problem: {problem}. Give me one unique, creative solution. Solution {id}:\"\n",
        ")\n",
        "\n",
        "branches = RunnableParallel(\n",
        "    sol1=prompt_branch.partial(id=\"1\") | llm | StrOutputParser(),\n",
        "    sol2=prompt_branch.partial(id=\"2\") | llm | StrOutputParser(),\n",
        "    sol3=prompt_branch.partial(id=\"3\") | llm | StrOutputParser(),\n",
        ")\n",
        "\n",
        "# Step 2: The Judge\n",
        "prompt_judge = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    I have three proposed solutions for: '{problem}'\n",
        "\n",
        "    1: {sol1}\n",
        "    2: {sol2}\n",
        "    3: {sol3}\n",
        "\n",
        "    Act as a Child Psychologist. Pick the most sustainable one (not bribery) and explain why.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Chain: Input -> Branches -> Judge -> Output\n",
        "tot_chain = (\n",
        "    RunnableParallel(problem=RunnableLambda(lambda x: x), branches=branches)\n",
        "    | (lambda x: {**x[\"branches\"], \"problem\": x[\"problem\"]})\n",
        "    | prompt_judge\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"--- Tree of Thoughts (ToT) Result ---\")\n",
        "print(tot_chain.invoke(problem))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "894940b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "894940b5",
        "outputId": "f748019e-df72-4d6b-c2a8-d4e2817e2e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Graph of Thoughts (GoT) Result ---\n",
            "In the mind-bending thriller \"Echoes of Eternity,\" brilliant physicist Dr. Sophia Ellis discovers a way to manipulate time, but her experiment goes catastrophically wrong, causing her consciousness to become trapped in a never-ending loop of past, present, and future. As she frantically tries to escape the paradox, she finds herself reliving the same pivotal moments in history, from the moon landing to the sinking of the Titanic, but each time with a twist - she's not alone. A mysterious and enigmatic figure, the \"Chrono,\" seems to be manipulating events from behind the scenes, and Sophia soon realizes that her only hope for survival lies in unraveling the mystery of the Chrono's true identity, a dashing and charismatic artist from a bygone era who may hold the key to her escape, but at a terrible cost: her own soul.\n"
          ]
        }
      ],
      "source": [
        "# 1. The Generator (Divergence)\n",
        "prompt_draft = ChatPromptTemplate.from_template(\n",
        "    \"Write a 1-sentence movie plot about: {topic}. Genre: {genre}.\"\n",
        ")\n",
        "\n",
        "drafts = RunnableParallel(\n",
        "    draft_scifi=prompt_draft.partial(genre=\"Sci-Fi\") | llm | StrOutputParser(),\n",
        "    draft_romance=prompt_draft.partial(genre=\"Romance\") | llm | StrOutputParser(),\n",
        "    draft_horror=prompt_draft.partial(genre=\"Horror\") | llm | StrOutputParser(),\n",
        ")\n",
        "\n",
        "# 2. The Aggregator (Convergence)\n",
        "prompt_combine = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    I have three movie ideas for the topic '{topic}':\n",
        "    1. Sci-Fi: {draft_scifi}\n",
        "    2. Romance: {draft_romance}\n",
        "    3. Horror: {draft_horror}\n",
        "\n",
        "    Your task: Create a new Mega-Movie that combines the TECHNOLOGY of Sci-Fi, the PASSION of Romance, and the FEAR of Horror.\n",
        "    Write one paragraph.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# 3. The Chain\n",
        "got_chain = (\n",
        "    RunnableParallel(topic=RunnableLambda(lambda x: x), drafts=drafts)\n",
        "    | (lambda x: {**x[\"drafts\"], \"topic\": x[\"topic\"]})\n",
        "    | prompt_combine\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"--- Graph of Thoughts (GoT) Result ---\")\n",
        "print(got_chain.invoke(\"Time Travel\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}